{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using paperXai to get your personal arXiv daily digest\n",
    "\n",
    "The goal of this notebook is to help you use this package and to understand the different components of the pipeline. Briefly, the pipeline can be decomposed into the following sections which will correspond to the sections of this notebook.\n",
    "\n",
    "- [Fetching the latest arXiv papers](#fetching-the-latest-arxiv-papers)\n",
    "- [Embedding predefined user questions and sections](#embedding-predefined-user-questions-and-sections)\n",
    "- [Semantic retrieval](#semantic-retrieval)\n",
    "- [Generating an automatic report](#generating-an-automatic-report)\n",
    "- [Sending the personalized newsletter](#sending-the-personalized-newsletter)\n",
    "\n",
    "For any comments, feel free to reach out directly (see [here](https://sebastianpartarrieu.github.io/)), or via an issue on the github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "import paperxai.constants as constants\n",
    "import paperxai.credentials as credentials\n",
    "from paperxai.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = credentials.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the latest arXiv papers\n",
    "\n",
    "See script `scripts/get_arxiv_papers.py` to fetch the documents using the arXiv API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ../scripts/get_arxiv_papers.py --max_results 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv(constants.ROOT_DIR + \"/data/arxiv/base_papers.csv\")\n",
    "df_new_articles = pd.read_csv(constants.ROOT_DIR + \"/data/arxiv/current_papers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding predefined user questions and sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding articles\n",
    "\n",
    "Let's embed the different articles we've obtained. We pay little attention here to performance, if you want to run this on a larger dataset, it may be worth batching calls and saving the embeddings in a dedicated array (vector database is definitely not useful at this scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /encodings/cl100k_base.tiktoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f74f4b14c70>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -3] Temporary failure in name resolution)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m LocationParseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/socket.py:954\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    953\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 954\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    955\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connection.py:210\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f74f4b14c70>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -3] Temporary failure in name resolution)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /encodings/cl100k_base.tiktoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f74f4b14c70>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -3] Temporary failure in name resolution)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/sebastian/Documents/MyCS/paperxai/notebooks/example_workflow.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sebastian/Documents/MyCS/paperxai/notebooks/example_workflow.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m openai_model \u001b[39m=\u001b[39m OpenAI(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sebastian/Documents/MyCS/paperxai/notebooks/example_workflow.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     chat_model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sebastian/Documents/MyCS/paperxai/notebooks/example_workflow.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     embedding_model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-embedding-ada-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sebastian/Documents/MyCS/paperxai/notebooks/example_workflow.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sebastian/Documents/MyCS/paperxai/notebooks/example_workflow.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sebastian/Documents/MyCS/paperxai/notebooks/example_workflow.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/MyCS/paperxai/src/paperxai/llms/openai.py:20\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, chat_model, embedding_model, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_model \u001b[39m=\u001b[39m chat_model\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m embedding_model\n\u001b[0;32m---> 20\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(provider\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mopenai\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemperature \u001b[39m=\u001b[39m temperature\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_tokens \u001b[39m=\u001b[39m max_tokens\n",
      "File \u001b[0;32m~/Documents/MyCS/paperxai/src/paperxai/llms/base.py:9\u001b[0m, in \u001b[0;36mBaseLLM.__init__\u001b[0;34m(self, provider)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, provider: \u001b[39mstr\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprovider \u001b[39m=\u001b[39m provider\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_tokenizer()\n\u001b[1;32m     10\u001b[0m     \u001b[39m# ensure that the tokenizer has an encode method\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, \u001b[39m\"\u001b[39m\u001b[39mencode\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mTokenizer must have an encode method\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/MyCS/paperxai/src/paperxai/llms/openai.py:25\u001b[0m, in \u001b[0;36mOpenAI.set_tokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_tokenizer\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m tiktoken\u001b[39m.\u001b[39;49mencoding_for_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_model)\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/tiktoken/model.py:75\u001b[0m, in \u001b[0;36mencoding_for_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m encoding_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not automatically map \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m to a tokeniser. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease use `tiktok.get_encoding` to explicitly get the tokeniser you expect.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m \u001b[39mreturn\u001b[39;00m get_encoding(encoding_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/tiktoken/registry.py:63\u001b[0m, in \u001b[0;36mget_encoding\u001b[0;34m(encoding_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown encoding \u001b[39m\u001b[39m{\u001b[39;00mencoding_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m constructor \u001b[39m=\u001b[39m ENCODING_CONSTRUCTORS[encoding_name]\n\u001b[0;32m---> 63\u001b[0m enc \u001b[39m=\u001b[39m Encoding(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconstructor())\n\u001b[1;32m     64\u001b[0m ENCODINGS[encoding_name] \u001b[39m=\u001b[39m enc\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m enc\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/tiktoken_ext/openai_public.py:64\u001b[0m, in \u001b[0;36mcl100k_base\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcl100k_base\u001b[39m():\n\u001b[0;32m---> 64\u001b[0m     mergeable_ranks \u001b[39m=\u001b[39m load_tiktoken_bpe(\n\u001b[1;32m     65\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mhttps://openaipublic.blob.core.windows.net/encodings/cl100k_base.tiktoken\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     66\u001b[0m     )\n\u001b[1;32m     67\u001b[0m     special_tokens \u001b[39m=\u001b[39m {\n\u001b[1;32m     68\u001b[0m         ENDOFTEXT: \u001b[39m100257\u001b[39m,\n\u001b[1;32m     69\u001b[0m         FIM_PREFIX: \u001b[39m100258\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m         ENDOFPROMPT: \u001b[39m100276\u001b[39m,\n\u001b[1;32m     73\u001b[0m     }\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     75\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcl100k_base\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     76\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpat_str\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m(?i:\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mve|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm|\u001b[39m\u001b[39m'\u001b[39m\u001b[39mll|\u001b[39m\u001b[39m'\u001b[39m\u001b[39md)|[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{L}\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{N}\u001b[39;00m\u001b[39m]?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{L}\u001b[39;00m\u001b[39m+|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{N}\u001b[39;00m\u001b[39m{\u001b[39m\u001b[39m1,3}| ?[^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{L}\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39mp\u001b[39m\u001b[39m{N}\u001b[39;00m\u001b[39m]+[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn]*|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mn]+|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+(?!\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS)|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+\u001b[39m\u001b[39m\"\"\"\u001b[39m,\n\u001b[1;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmergeable_ranks\u001b[39m\u001b[39m\"\u001b[39m: mergeable_ranks,\n\u001b[1;32m     78\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspecial_tokens\u001b[39m\u001b[39m\"\u001b[39m: special_tokens,\n\u001b[1;32m     79\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/tiktoken/load.py:116\u001b[0m, in \u001b[0;36mload_tiktoken_bpe\u001b[0;34m(tiktoken_bpe_file)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_tiktoken_bpe\u001b[39m(tiktoken_bpe_file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mbytes\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[1;32m    115\u001b[0m     \u001b[39m# NB: do not add caching to this function\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     contents \u001b[39m=\u001b[39m read_file_cached(tiktoken_bpe_file)\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    118\u001b[0m         base64\u001b[39m.\u001b[39mb64decode(token): \u001b[39mint\u001b[39m(rank)\n\u001b[1;32m    119\u001b[0m         \u001b[39mfor\u001b[39;00m token, rank \u001b[39min\u001b[39;00m (line\u001b[39m.\u001b[39msplit() \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m contents\u001b[39m.\u001b[39msplitlines() \u001b[39mif\u001b[39;00m line)\n\u001b[1;32m    120\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/tiktoken/load.py:48\u001b[0m, in \u001b[0;36mread_file_cached\u001b[0;34m(blobpath)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(cache_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     46\u001b[0m         \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> 48\u001b[0m contents \u001b[39m=\u001b[39m read_file(blobpath)\n\u001b[1;32m     50\u001b[0m os\u001b[39m.\u001b[39mmakedirs(cache_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m tmp_filename \u001b[39m=\u001b[39m cache_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid4()) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.tmp\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/tiktoken/load.py:24\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(blobpath)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m     23\u001b[0m \u001b[39m# avoiding blobfile for public files helps avoid auth issues, like MFA prompts\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m resp \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(blobpath)\n\u001b[1;32m     25\u001b[0m resp\u001b[39m.\u001b[39mraise_for_status()\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m resp\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/llms/lib/python3.9/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /encodings/cl100k_base.tiktoken (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f74f4b14c70>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno -3] Temporary failure in name resolution)\"))"
     ]
    }
   ],
   "source": [
    "openai_model = OpenAI(\n",
    "    chat_model=\"gpt-3.5-turbo\",\n",
    "    embedding_model=\"text-embedding-ada-002\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_articles[\"Embeddings\"] = df_new_articles[\"String_representation\"].apply(\n",
    "    lambda x: openai_model.get_embeddings(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_articles.to_csv(\n",
    "#     constants.ROOT_DIR + \"/data/arxiv/current_papers_with_embeddings.csv\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_embeddings = np.vstack(df_new_articles[\"Embeddings\"].values)\n",
    "np.save(constants.ROOT_DIR + \"/data/arxiv/article_embeddings.npy\", article_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paperxai.report.retriever import ReportRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ReportRetriever(language_model=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>String_representation</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmarking and Analyzing Generative Data for...</td>\n",
       "      <td>http://arxiv.org/abs/2307.13697v1</td>\n",
       "      <td>Advancements in large pre-trained generative m...</td>\n",
       "      <td>Bo Li, Haotian Liu, Liangyu Chen, Yong Jae Lee...</td>\n",
       "      <td>2023-07-25T17:59:59Z</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2307.13697v1</td>\n",
       "      <td>Title: Benchmarking and Analyzing Generative D...</td>\n",
       "      <td>[-0.03855739  0.01224458 -0.00347183 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evaluating Large Language Models for Radiology...</td>\n",
       "      <td>http://arxiv.org/abs/2307.13693v1</td>\n",
       "      <td>The rise of large language models (LLMs) has m...</td>\n",
       "      <td>Zhengliang Liu, Tianyang Zhong, Yiwei Li, Yuto...</td>\n",
       "      <td>2023-07-25T17:57:18Z</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2307.13693v1</td>\n",
       "      <td>Title: Evaluating Large Language Models for Ra...</td>\n",
       "      <td>[-0.01048704  0.03709306  0.02674473 ... -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARB: Advanced Reasoning Benchmark for Large La...</td>\n",
       "      <td>http://arxiv.org/abs/2307.13692v1</td>\n",
       "      <td>Large Language Models (LLMs) have demonstrated...</td>\n",
       "      <td>Tomohiro Sawada, Daniel Paleka, Alexander Havr...</td>\n",
       "      <td>2023-07-25T17:55:19Z</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2307.13692v1</td>\n",
       "      <td>Title: ARB: Advanced Reasoning Benchmark for L...</td>\n",
       "      <td>[ 0.0065059   0.0015553  -0.00759198 ... -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Visual Language of Fabrics</td>\n",
       "      <td>http://arxiv.org/abs/2307.13681v1</td>\n",
       "      <td>We introduce text2fabric, a novel dataset that...</td>\n",
       "      <td>Valentin Deschaintre, Julia Guerrero-Viu, Dieg...</td>\n",
       "      <td>2023-07-25T17:39:39Z</td>\n",
       "      <td>cs.GR</td>\n",
       "      <td>2307.13681v1</td>\n",
       "      <td>Title: The Visual Language of Fabrics\\nAbstrac...</td>\n",
       "      <td>[-0.01458119  0.01483235  0.00258485 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High Probability Analysis for Non-Convex Stoch...</td>\n",
       "      <td>http://arxiv.org/abs/2307.13680v1</td>\n",
       "      <td>Gradient clipping is a commonly used technique...</td>\n",
       "      <td>Shaojie Li, Yong Liu</td>\n",
       "      <td>2023-07-25T17:36:56Z</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2307.13680v1</td>\n",
       "      <td>Title: High Probability Analysis for Non-Conve...</td>\n",
       "      <td>[-0.00973936 -0.01733373  0.02210196 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Technical Challenges of Deploying Reinforcemen...</td>\n",
       "      <td>http://arxiv.org/abs/2307.11105v1</td>\n",
       "      <td>Going from research to production, especially ...</td>\n",
       "      <td>Jonas Gillberg, Joakim Bergdahl, Alessandro Se...</td>\n",
       "      <td>2023-07-19T18:19:23Z</td>\n",
       "      <td>cs.SE</td>\n",
       "      <td>2307.11105v1</td>\n",
       "      <td>Title: Technical Challenges of Deploying Reinf...</td>\n",
       "      <td>[ 0.00047117 -0.0138482   0.01550069 ... -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>TokenFlow: Consistent Diffusion Features for C...</td>\n",
       "      <td>http://arxiv.org/abs/2307.10373v2</td>\n",
       "      <td>The generative AI revolution has recently expa...</td>\n",
       "      <td>Michal Geyer, Omer Bar-Tal, Shai Bagon, Tali D...</td>\n",
       "      <td>2023-07-19T18:00:03Z</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2307.10373v2</td>\n",
       "      <td>Title: TokenFlow: Consistent Diffusion Feature...</td>\n",
       "      <td>[-0.02155961 -0.00051334 -0.02008521 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>A Decision Making Framework for Recommended Ma...</td>\n",
       "      <td>http://arxiv.org/abs/2307.10085v2</td>\n",
       "      <td>With the rapid development of global road tran...</td>\n",
       "      <td>Haoyu Sun, Yan Yan</td>\n",
       "      <td>2023-07-19T15:55:25Z</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>2307.10085v2</td>\n",
       "      <td>Title: A Decision Making Framework for Recomme...</td>\n",
       "      <td>[ 0.0290125   0.00111448 -0.00454689 ... -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>An Empirical Study on Fertility Proposals Usin...</td>\n",
       "      <td>http://arxiv.org/abs/2307.10025v2</td>\n",
       "      <td>Fertility issues are closely related to popula...</td>\n",
       "      <td>Yulin Zhou</td>\n",
       "      <td>2023-07-19T15:09:50Z</td>\n",
       "      <td>cs.HC</td>\n",
       "      <td>2307.10025v2</td>\n",
       "      <td>Title: An Empirical Study on Fertility Proposa...</td>\n",
       "      <td>[ 0.00313848 -0.0060077   0.0023272  ... -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Generating Mathematical Derivations with Large...</td>\n",
       "      <td>http://arxiv.org/abs/2307.09998v2</td>\n",
       "      <td>The derivation of mathematical results in spec...</td>\n",
       "      <td>Jordan Meadows, Marco Valentino, Andre Freitas</td>\n",
       "      <td>2023-07-19T14:13:02Z</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>2307.09998v2</td>\n",
       "      <td>Title: Generating Mathematical Derivations wit...</td>\n",
       "      <td>[-0.00173682  0.01786548 -0.01089306 ... -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Benchmarking and Analyzing Generative Data for...   \n",
       "1    Evaluating Large Language Models for Radiology...   \n",
       "2    ARB: Advanced Reasoning Benchmark for Large La...   \n",
       "3                       The Visual Language of Fabrics   \n",
       "4    High Probability Analysis for Non-Convex Stoch...   \n",
       "..                                                 ...   \n",
       "700  Technical Challenges of Deploying Reinforcemen...   \n",
       "701  TokenFlow: Consistent Diffusion Features for C...   \n",
       "702  A Decision Making Framework for Recommended Ma...   \n",
       "703  An Empirical Study on Fertility Proposals Usin...   \n",
       "704  Generating Mathematical Derivations with Large...   \n",
       "\n",
       "                                   URL  \\\n",
       "0    http://arxiv.org/abs/2307.13697v1   \n",
       "1    http://arxiv.org/abs/2307.13693v1   \n",
       "2    http://arxiv.org/abs/2307.13692v1   \n",
       "3    http://arxiv.org/abs/2307.13681v1   \n",
       "4    http://arxiv.org/abs/2307.13680v1   \n",
       "..                                 ...   \n",
       "700  http://arxiv.org/abs/2307.11105v1   \n",
       "701  http://arxiv.org/abs/2307.10373v2   \n",
       "702  http://arxiv.org/abs/2307.10085v2   \n",
       "703  http://arxiv.org/abs/2307.10025v2   \n",
       "704  http://arxiv.org/abs/2307.09998v2   \n",
       "\n",
       "                                              Abstract  \\\n",
       "0    Advancements in large pre-trained generative m...   \n",
       "1    The rise of large language models (LLMs) has m...   \n",
       "2    Large Language Models (LLMs) have demonstrated...   \n",
       "3    We introduce text2fabric, a novel dataset that...   \n",
       "4    Gradient clipping is a commonly used technique...   \n",
       "..                                                 ...   \n",
       "700  Going from research to production, especially ...   \n",
       "701  The generative AI revolution has recently expa...   \n",
       "702  With the rapid development of global road tran...   \n",
       "703  Fertility issues are closely related to popula...   \n",
       "704  The derivation of mathematical results in spec...   \n",
       "\n",
       "                                               Authors        Published Date  \\\n",
       "0    Bo Li, Haotian Liu, Liangyu Chen, Yong Jae Lee...  2023-07-25T17:59:59Z   \n",
       "1    Zhengliang Liu, Tianyang Zhong, Yiwei Li, Yuto...  2023-07-25T17:57:18Z   \n",
       "2    Tomohiro Sawada, Daniel Paleka, Alexander Havr...  2023-07-25T17:55:19Z   \n",
       "3    Valentin Deschaintre, Julia Guerrero-Viu, Dieg...  2023-07-25T17:39:39Z   \n",
       "4                                 Shaojie Li, Yong Liu  2023-07-25T17:36:56Z   \n",
       "..                                                 ...                   ...   \n",
       "700  Jonas Gillberg, Joakim Bergdahl, Alessandro Se...  2023-07-19T18:19:23Z   \n",
       "701  Michal Geyer, Omer Bar-Tal, Shai Bagon, Tali D...  2023-07-19T18:00:03Z   \n",
       "702                                 Haoyu Sun, Yan Yan  2023-07-19T15:55:25Z   \n",
       "703                                         Yulin Zhou  2023-07-19T15:09:50Z   \n",
       "704     Jordan Meadows, Marco Valentino, Andre Freitas  2023-07-19T14:13:02Z   \n",
       "\n",
       "    Category      Paper ID                              String_representation  \\\n",
       "0      cs.CV  2307.13697v1  Title: Benchmarking and Analyzing Generative D...   \n",
       "1      cs.CL  2307.13693v1  Title: Evaluating Large Language Models for Ra...   \n",
       "2      cs.CL  2307.13692v1  Title: ARB: Advanced Reasoning Benchmark for L...   \n",
       "3      cs.GR  2307.13681v1  Title: The Visual Language of Fabrics\\nAbstrac...   \n",
       "4      cs.LG  2307.13680v1  Title: High Probability Analysis for Non-Conve...   \n",
       "..       ...           ...                                                ...   \n",
       "700    cs.SE  2307.11105v1  Title: Technical Challenges of Deploying Reinf...   \n",
       "701    cs.CV  2307.10373v2  Title: TokenFlow: Consistent Diffusion Feature...   \n",
       "702    cs.AI  2307.10085v2  Title: A Decision Making Framework for Recomme...   \n",
       "703    cs.HC  2307.10025v2  Title: An Empirical Study on Fertility Proposa...   \n",
       "704    cs.CL  2307.09998v2  Title: Generating Mathematical Derivations wit...   \n",
       "\n",
       "                                            Embeddings  \n",
       "0    [-0.03855739  0.01224458 -0.00347183 ... -0.01...  \n",
       "1    [-0.01048704  0.03709306  0.02674473 ... -0.00...  \n",
       "2    [ 0.0065059   0.0015553  -0.00759198 ... -0.03...  \n",
       "3    [-0.01458119  0.01483235  0.00258485 ... -0.01...  \n",
       "4    [-0.00973936 -0.01733373  0.02210196 ... -0.01...  \n",
       "..                                                 ...  \n",
       "700  [ 0.00047117 -0.0138482   0.01550069 ... -0.04...  \n",
       "701  [-0.02155961 -0.00051334 -0.02008521 ... -0.01...  \n",
       "702  [ 0.0290125   0.00111448 -0.00454689 ... -0.01...  \n",
       "703  [ 0.00313848 -0.0060077   0.0023272  ... -0.00...  \n",
       "704  [-0.00173682  0.01786548 -0.01089306 ... -0.00...  \n",
       "\n",
       "[705 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an automatic report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending the personalized newsletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
